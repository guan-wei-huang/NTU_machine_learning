{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeZtEkZdNMGg"
      },
      "source": [
        "## ML HW2 手把手教學 \n",
        "\n",
        "### Logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lMOeb2gcNWdB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLvVaOeANqmH"
      },
      "source": [
        "We only use one-hot-encoding feature here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U4uvD-jLNrWM"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    x_train = pd.read_csv('X_train')\n",
        "    x_test = pd.read_csv('X_test')\n",
        "\n",
        "    x_train = x_train.values\n",
        "    x_test = x_test.values\n",
        "\n",
        "    y_train = pd.read_csv('Y_train', header = None)\n",
        "    y_train = y_train.values\n",
        "    y_train = y_train.reshape(-1)\n",
        "\n",
        "\n",
        "    print(x_train.shape)\n",
        "    print(x_test.shape)\n",
        "    return x_train, y_train, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiXhvsEgPgET"
      },
      "source": [
        "*Use* np.clip to prevent overflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EyRSayVjPk19"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    res = 1 / (1.0 + np.exp(-z))\n",
        "    return np.clip(res, 1e-6, 1-1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XvUJFu5gP1ac"
      },
      "outputs": [],
      "source": [
        "def normalize(x_train, x_test):\n",
        "    x_all = np.concatenate((x_train, x_test), axis = 0)\n",
        "    mean = np.mean(x_all, axis = 0)\n",
        "    std = np.std(x_all, axis = 0)\n",
        "\n",
        "    index = [0, 1, 3, 4, 5]\n",
        "    mean_vec = np.zeros(x_all.shape[1])\n",
        "    std_vec = np.ones(x_all.shape[1])\n",
        "    mean_vec[index] = mean[index]\n",
        "    std_vec[index] = std[index]\n",
        "\n",
        "    x_all_nor = (x_all - mean_vec) / std_vec\n",
        "\n",
        "    x_train_nor = x_all_nor[0:x_train.shape[0]]\n",
        "    x_test_nor = x_all_nor[x_train.shape[0]:]\n",
        "\n",
        "    return x_train_nor, x_test_nor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txYrOUqsQKCD"
      },
      "source": [
        "Gradient descent using adagrad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uA3DI4BzQN6l"
      },
      "outputs": [],
      "source": [
        "def train(x_train, y_train):\n",
        "    b = 0.0\n",
        "    w = np.zeros(x_train.shape[1])\n",
        "    lr = 0.001\n",
        "    epoch = 500\n",
        "    b_lr = 0\n",
        "    w_lr = np.ones(x_train.shape[1])\n",
        "    batch_size = 512\n",
        "    t = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # implementation of gradient descent\n",
        "        index = np.arange(x_train.shape[0])\n",
        "        np.random.shuffle(index)\n",
        "        x_train, y_train = x_train[index], y_train[index]\n",
        "        \n",
        "        for i in range(int(x_train.shape[0]/batch_size)):\n",
        "          t += 1\n",
        "          x = x_train[i * batch_size: (i+1) * batch_size]\n",
        "          y = y_train[i * batch_size: (i+1) * batch_size]\n",
        "\n",
        "          z = np.dot(x, w)+b\n",
        "          zz = sigmoid(z)\n",
        "          loss = y - zz\n",
        "\n",
        "          w_g = (-2) * np.dot(loss, x)\n",
        "          b_g = (-2) * np.sum(loss)\n",
        "          w_lr = w_lr + w_g ** 2\n",
        "          b_lr = b_lr + b_g ** 2\n",
        "\n",
        "          w = w - lr/np.sqrt(w_lr/t) * w_g\n",
        "          b = b - lr/np.sqrt(b_lr/t) * b_g\n",
        "          \n",
        "          if e%100 == 0:          \n",
        "            zz[zz >= 0.5] = 1\n",
        "            zz[zz < 0.5] = 0\n",
        "            acc = y - zz #shape: (32561,)\n",
        "            acc[acc == 0] = 2\n",
        "            acc[acc != 2] = 0\n",
        "            print('epoch:{}\\n Accuracy:{}%\\n'.format(t+1, np.sum(acc) * 50 / acc.shape[0]))\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClofrDqhQVU8"
      },
      "source": [
        "新增區段"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45tuF_lJQVos",
        "outputId": "b879db1e-049a-44b9-9439-fe9fe59cdaea"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test = load_data()\n",
        "x_train, x_test = normalize(x_train, x_test)\n",
        "\n",
        "w, b = train(x_train, y_train)\n",
        "\n",
        "y_test = np.matmul(x_test, w) + b\n",
        "y_test[y_test >= 0.5] = 1\n",
        "y_test[y_test < 0.5] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RIt0Lf5Horbh"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('predict.csv', 'w', newline='') as csvf:\n",
        "    # 建立 CSV 檔寫入器\n",
        "    writer = csv.writer(csvf)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i in range(int(y_test.shape[0])):\n",
        "      writer.writerow( [i + 1, int(y_test[i])] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3aDCdTxXo-B"
      },
      "source": [
        "### Tip for math problem\n",
        "[p1](https://people.eecs.berkeley.edu/~jrs/189/exam/mids14.pdf)  \n",
        "[p2&3](https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf)  \n",
        "[p3](https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "「ML_HW2_logistic.ipynb」的副本",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
