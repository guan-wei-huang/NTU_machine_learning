{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "「hw4_sample_code.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPxdfd1Apt3_"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaCn_Xokpt4C"
      },
      "source": [
        "DEVICE_NUM = 2\n",
        "BATCH_SIZE = 128\n",
        "EPOCH_NUM = 50\n",
        "MAX_POSITIONS_LEN = 500\n",
        "SEED = 5566\n",
        "MODEL_DIR = 'model.pth'\n",
        "lr = 0.001\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "#torch.cuda.set_device(DEVICE_NUM)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "w2v_config = {'path': 'w2v.model', 'dim': 256}\n",
        "lstm_config = {'hidden_dim': 256, 'num_layers': 2, 'bidirectional': True, 'fix_embedding': True}\n",
        "header_config = {'dropout': 0.3, 'hidden_dim': 512}\n",
        "assert header_config['hidden_dim'] == lstm_config['hidden_dim'] or header_config['hidden_dim'] == lstm_config['hidden_dim'] * 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB6dR8krpt4C"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "def parsing_text(text):\n",
        "    # TODO: do data processing\n",
        "    #print('origin: ', text)\n",
        "    text = str(text)\n",
        "    #text = text.replace(' \\' ', '')\n",
        "    texts = text.split(' ')\n",
        "    #for idx, t in enumerate(texts):\n",
        "     # texts[idx] = ps.stem(texts[idx]) \n",
        "    #print('after replace: ', text)\n",
        "\n",
        "    return texts\n",
        "\n",
        "def load_train_label(path='train_label.csv'):\n",
        "    tra_lb_pd = pd.read_csv(path)\n",
        "    label = torch.FloatTensor(tra_lb_pd['label'].values)\n",
        "    idx = tra_lb_pd['id'].tolist()\n",
        "    #text = [parsing_text(s).split(' ') for s in tra_lb_pd['text'].tolist()]\n",
        "    text = [parsing_text(s) for s in tra_lb_pd['text'].tolist()]\n",
        "    return idx, text, label\n",
        "\n",
        "def load_train_nolabel(path='train_nolabel.csv'):\n",
        "    tra_nlb_pd = pd.read_csv(path)\n",
        "    #text = [parsing_text(s).split(' ') for s in tra_nlb_pd['text'].tolist()]\n",
        "    text = [parsing_text(s) for s in tra_nlb_pd['text'].tolist()]\n",
        "    return text\n",
        "\n",
        "def load_test(path='test.csv'):\n",
        "    tst_pd = pd.read_csv(path)\n",
        "    idx = tst_pd['id'].tolist()\n",
        "#   text = [parsing_text(s).split(' ') for s in tst_pd['text'].tolist()]\n",
        "    text = [parsing_text(s) for s in tst_pd['text'].tolist()]\n",
        "    return idx, text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAX6laKypt4D"
      },
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self, sentences, w2v_config):\n",
        "        self.sentences = sentences\n",
        "        self.idx2word = []\n",
        "        self.word2idx = {}\n",
        "        self.embedding_matrix = []\n",
        "        self.build_word2vec(sentences, **w2v_config)\n",
        "        \n",
        "    def build_word2vec(self, x, path, dim):\n",
        "        if os.path.isfile(path):\n",
        "            print(\"loading word2vec model ...\")\n",
        "            w2v_model = Word2Vec.load(path)\n",
        "        else:\n",
        "            print(\"training word2vec model ...\")\n",
        "            w2v_model = Word2Vec(x, size=dim, window=5, min_count=2, workers=12, iter=2, sg=1)\n",
        "            print(\"saving word2vec model ...\")\n",
        "            w2v_model.save(path)\n",
        "            \n",
        "        self.embedding_dim = w2v_model.vector_size\n",
        "        for i, word in enumerate(w2v_model.wv.vocab):\n",
        "            #e.g. self.word2index['he'] = 1 \n",
        "            #e.g. self.index2word[1] = 'he'\n",
        "            #e.g. self.vectors[1] = 'he' vector\n",
        "            \n",
        "            self.word2idx[word] = len(self.word2idx)\n",
        "            self.idx2word.append(word)\n",
        "            self.embedding_matrix.append(w2v_model[word])\n",
        "        \n",
        "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
        "        self.add_embedding('<PAD>')\n",
        "        self.add_embedding('<UNK>')\n",
        "        print(\"total words: {}\".format(len(self.embedding_matrix)))\n",
        "        \n",
        "    def add_embedding(self, word):\n",
        "        # 把 word 加進 embedding，並賦予他一個隨機生成的 representation vector\n",
        "        # word 只會是 \"<PAD>\" 或 \"<UNK>\"\n",
        "        vector = torch.empty(1, self.embedding_dim)\n",
        "        torch.nn.init.uniform_(vector)\n",
        "        self.word2idx[word] = len(self.word2idx)\n",
        "        self.idx2word.append(word)\n",
        "        self.embedding_matrix = torch.cat([self.embedding_matrix, vector], 0)   \n",
        "        \n",
        "    def sentence2idx(self, sentence):\n",
        "        sentence_idx = []\n",
        "        for word in sentence:\n",
        "            if word in self.word2idx.keys():\n",
        "                sentence_idx.append(self.word2idx[word])\n",
        "            else:\n",
        "                sentence_idx.append(self.word2idx[\"<UNK>\"])\n",
        "        return torch.LongTensor(sentence_idx)\n",
        "    \n",
        "class TwitterDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, id_list, sentences, labels, preprocessor):\n",
        "        self.id_list = id_list\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.preprocessor = preprocessor\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is None: return self.id_list[idx], self.preprocessor.sentence2idx(self.sentences[idx])\n",
        "        return self.id_list[idx], self.preprocessor.sentence2idx(self.sentences[idx]), self.labels[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def collate_fn(self, data):\n",
        "        id_list = torch.LongTensor([d[0] for d in data])\n",
        "        lengths = torch.LongTensor([len(d[1]) for d in data])\n",
        "        texts = pad_sequence(\n",
        "            [d[1] for d in data], batch_first=True).contiguous()\n",
        "     \n",
        "        if self.labels is None: \n",
        "            return id_list, lengths, texts\n",
        "        \n",
        "        labels = torch.FloatTensor([d[2] for d in data])\n",
        "        return id_list, lengths, texts, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6KNphAgpt4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5566215b-5bf7-4524-fa32-febc4778430d"
      },
      "source": [
        "train_idx, train_label_text, label = load_train_label('train_label.csv')\n",
        "train_nolabel_text = load_train_nolabel()\n",
        "#preprocessor = Preprocessor(train_label_text, w2v_config)\n",
        "preprocessor = Preprocessor(train_nolabel_text, w2v_config)\n",
        "\n",
        "\n",
        "train_idx, valid_idx, train_label_text, valid_label_text, train_label, valid_label = train_test_split(train_idx, train_label_text, label, test_size=0.12)\n",
        "train_dataset, valid_dataset = TwitterDataset(train_idx, train_label_text, train_label, preprocessor), TwitterDataset(valid_idx, valid_label_text, valid_label, preprocessor)\n",
        "\n",
        "test_idx, test_text = load_test('test.csv')\n",
        "test_dataset = TwitterDataset(test_idx, test_text, None, preprocessor)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = True,\n",
        "                                            collate_fn = train_dataset.collate_fn,\n",
        "                                            num_workers = 8)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset = valid_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = False,\n",
        "                                            collate_fn = valid_dataset.collate_fn,\n",
        "                                            num_workers = 8)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = False,\n",
        "                                            collate_fn = test_dataset.collate_fn,\n",
        "                                            num_workers = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word2vec model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total words: 77279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-_G6vsIpt4E"
      },
      "source": [
        "class LSTM_Backbone(torch.nn.Module):\n",
        "    def __init__(self, embedding, hidden_dim, num_layers, bidirectional, fix_embedding=True):\n",
        "        super(LSTM_Backbone, self).__init__()\n",
        "        self.embedding = torch.nn.Embedding(embedding.size(0),embedding.size(1))\n",
        "        self.embedding.weight = torch.nn.Parameter(embedding)\n",
        "        self.embedding.weight.requires_grad = False if fix_embedding else True\n",
        "        \n",
        "        self.lstm = torch.nn.LSTM(embedding.size(1), hidden_dim, num_layers=num_layers, \\\n",
        "                                  bidirectional=bidirectional, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.embedding(inputs)\n",
        "        x, _ = self.lstm(inputs)\n",
        "        return x\n",
        "    \n",
        "class Header(torch.nn.Module):\n",
        "    def __init__(self, dropout, hidden_dim):\n",
        "        super(Header, self).__init__()\n",
        "        # TODO: you should design your classifier module\n",
        "        #self.classifier = torch.nn.Sequential(torch.nn.Dropout(0.5),\n",
        "                                        #  torch.nn.Linear(hidden_dim, 256),\n",
        "                                        #  torch.nn.Dropout(0.3),\n",
        "                                        #  torch.nn.ReLU(),\n",
        "                                        #  torch.nn.Linear(256, 1),\n",
        "                                        #  torch.nn.Sigmoid())\n",
        "        self.classifier = torch.nn.Sequential(torch.nn.Linear(512, 128),\n",
        "                                         torch.nn.Dropout(0.5),\n",
        "                                         torch.nn.Linear(128, 1),\n",
        "                                         torch.nn.Sigmoid())\n",
        "    @ torch.no_grad()\n",
        "    def _get_length_masks(self, lengths):\n",
        "        # lengths: (batch_size, ) in cuda\n",
        "        ascending = torch.arange(MAX_POSITIONS_LEN)[:lengths.max().item()].unsqueeze(\n",
        "            0).expand(len(lengths), -1).to(lengths.device)\n",
        "        length_masks = (ascending < lengths.unsqueeze(-1)).unsqueeze(-1)\n",
        "        return length_masks\n",
        "    \n",
        "    def forward(self, inputs, lengths):\n",
        "        # the input shape should be (N, L, D∗H)\n",
        "        pad_mask = self._get_length_masks(lengths)\n",
        "        inputs = inputs * pad_mask\n",
        "        inputs = inputs.sum(dim=1)\n",
        "        out = self.classifier(inputs).squeeze()\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEbChegipt4E"
      },
      "source": [
        "def train(train_loader, backbone, header, optimizer, criterion, device, epoch):\n",
        "\n",
        "    total_loss = []\n",
        "    total_acc = []\n",
        "    \n",
        "    for i, (idx_list, lengths, texts, labels) in enumerate(train_loader):\n",
        "        lengths, inputs, labels = lengths.to(device), texts.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        if not backbone is None:\n",
        "            inputs = backbone(inputs)\n",
        "        soft_predicted = header(inputs, lengths)\n",
        "        loss = criterion(soft_predicted, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            hard_predicted = (soft_predicted >= 0.5).int()\n",
        "            correct = sum(hard_predicted == labels).item()\n",
        "            batch_size = len(labels)\n",
        "        \n",
        "        print('[ Epoch {}: {}/{} ] loss:{:.3f} acc:{:.3f} '.format(epoch+1, i+1, len(train_loader), loss.item(), correct * 100 / batch_size), end='\\r')\n",
        "\n",
        "def valid(valid_loader, backbone, header, criterion, device, epoch):\n",
        "    backbone.eval()\n",
        "    header.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss = []\n",
        "        total_acc = []\n",
        "        \n",
        "        for i, (idx_list, lengths, texts, labels) in enumerate(valid_loader):\n",
        "            lengths, inputs, labels = lengths.to(device), texts.to(device), labels.to(device)\n",
        "\n",
        "            if not backbone is None:\n",
        "                inputs = backbone(inputs)\n",
        "            soft_predicted = header(inputs, lengths)\n",
        "            loss = criterion(soft_predicted, labels)\n",
        "            total_loss.append(loss.item())\n",
        "            \n",
        "            hard_predicted = (soft_predicted >= 0.5).int()\n",
        "            correct = sum(hard_predicted == labels).item()\n",
        "            acc = correct * 100 / len(labels)\n",
        "            total_acc.append(acc)\n",
        "            \n",
        "            print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f}'.format(epoch+1, np.mean(total_loss), np.mean(total_acc)), end='\\r')\n",
        "    backbone.train()\n",
        "    header.train()\n",
        "    return np.mean(total_loss), np.mean(total_acc)\n",
        "\n",
        "            \n",
        "def run_training(train_loader, valid_loader, backbone, header, epoch_num, lr, device, model_dir): \n",
        "    acc_record = []\n",
        "    max_acc = 0\n",
        "    count = 0\n",
        "    def check_point(backbone, header, loss, acc, model_dir):\n",
        "        # TODO\n",
        "        if acc >= np.mean(acc_record[-5:]):    \n",
        "            print('model saved')\n",
        "            torch.save({'backbone': backbone, 'header': header}, model_dir)\n",
        "    def is_stop(loss, acc):\n",
        "        # TODO\n",
        "        # if acc < max_acc:\n",
        "        #   count += 1\n",
        "        # else:\n",
        "        #   global max_acc = acc\n",
        "        #   count = 0\n",
        "        return False\n",
        "    \n",
        "    if backbone is None:\n",
        "        trainable_paras = header.parameters()\n",
        "    else:\n",
        "        trainable_paras = list(backbone.parameters()) + list(header.parameters())\n",
        "        \n",
        "    optimizer = torch.optim.Adam(trainable_paras, lr=lr, weight_decay=1e-5)\n",
        "    \n",
        "    backbone.train()\n",
        "    header.train()\n",
        "    backbone = backbone.to(device)\n",
        "    header = header.to(device)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    for epoch in range(epoch_num):\n",
        "        train(train_loader, backbone, header, optimizer, criterion, device, epoch)\n",
        "        loss, acc = valid(valid_loader, backbone, header, criterion, device, epoch)\n",
        "        print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f} '.format(epoch+1, loss, acc))\n",
        "        \n",
        "        acc_record.append(acc)\n",
        "        check_point(backbone, header, loss, acc, model_dir)\n",
        "        \n",
        "        if acc < max_acc:\n",
        "          count += 1\n",
        "        else:\n",
        "          max_acc = acc\n",
        "          count = 0\n",
        "        if count == 4:\n",
        "          break\n",
        "#        if is_stop(loss, acc):\n",
        "#            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHS1ry-7pt4F"
      },
      "source": [
        "backbone = LSTM_Backbone(preprocessor.embedding_matrix, **lstm_config)\n",
        "header = Header(**header_config)\n",
        "\n",
        "run_training(train_loader, valid_loader, backbone, header, EPOCH_NUM, lr, device, MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz8PUufgpt4F"
      },
      "source": [
        "def run_testing(test_loader, backbone, header, device, output_path):\n",
        "    with open(output_path, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['id', 'label'])\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for i, (idx_list, lengths, texts) in enumerate(test_loader):\n",
        "                lengths, inputs = lengths.to(device), texts.to(device)\n",
        "                if not backbone is None:\n",
        "                    inputs = backbone(inputs)\n",
        "                soft_predicted = header(inputs, lengths)\n",
        "                hard_predicted = (soft_predicted >= 0.5).int()\n",
        "                for i, p in zip(idx_list, hard_predicted):\n",
        "                    writer.writerow([str(i.item()), str(p.item())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY-2YKU6pt4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd071dc-87df-4b23-c768-35bfb6f8b362"
      },
      "source": [
        "run_testing(test_loader, backbone, header, device, 'pred.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GjyXU3Mpt4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1571953-0bde-472f-a584-cc7c4dc0f591"
      },
      "source": [
        "test_idx, test_text = load_test('a.csv')\n",
        "test_dataset = TwitterDataset(test_idx, test_text, None, preprocessor)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = False,\n",
        "                                            collate_fn = test_dataset.collate_fn,\n",
        "                                            num_workers = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sruyO4uUpt4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945226d3-de45-4402-d556-80181e725dd0"
      },
      "source": [
        "run_testing(test_loader, backbone, header, device, 'pred.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    }
  ]
}